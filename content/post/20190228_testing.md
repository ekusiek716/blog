---
date: 2019-02-10T18:57:03+09:00
title: "テストする"
draft: true
categories: ["Product"]
description: ""
eyecatch: "/images/top-ogp.jpg"
tags: ["Product"]
author: "Yamotty"
---

プロダクトをちゃんとテスト（実験）する、というのを大事にしており、その際にケアしていることを書いてみた。

## 3つの不確実性

テストの話の前に、3つのリスクについて前置きしたい。

プロダクトというのは「こういう課題をユーザーはもっているだろう」という洞察から始まり、「こうやったらうまく解決できるのではないか」という仮説を具体的な形にして、誰かへ提供することからスタートする。提供はゴールではなく「スタート」だ。なぜか。

殆どの場合で、プロダクトのバージョン1は以下の3つのうち、どれか、もしくは全てを抱えている。

1. **熱量の不確実性** （プロダクトが解決しようとした課題が存在しないか、弱い）
2. **サイズの不確実性** （課題は存在したが、極めて少ない人しか対象ではなかった）
3. **解法の不確実性** （解決方法が適切ではなかった）

1から3はどれも無視不可能な問題で、一昔前であれば、「リリースしたら誰も欲しがるものではなかった、どうしよう」となっていた。

そこからユーザーに「なんで使わへんの？」とヒアリングして、ユーザーが言ったことを真にうけてプロダクトに反映する。多くのユーザーは「本当に欲しいもの」を知らないので、これによってプロダクトの死を早めたりする。もしくはあの手この手でマーケティングをし、市場流通量がピークにきたところで誰もリテンションせず静かに終わりを迎えたりする。

特に製造に多くの月日がかかり、大きく成熟したマーケットでの新規事業にこの類の失敗が多かった。自動車や家電、不動産などだ。こういうプロダクトの失敗はなかなか共有されることはないが、「失敗の研究」という本に沢山の事例が載っており、時代や商材を超えて勉強になる。

## 検証手段の抱負なSensor時代

現代の我々は非常に良い時代に生きている。デジタルのプロダクトも、アナログのプロダクトも高度なセンシング技術を活用することができる。プロダクトを誰がどう使ったのか、逆にどう使わなかったのかについて、多くのデータを集めることができる。

リリースがゴールではなくスタートだ、と言ったのは「ユーザーから”嘘”のないフィードバックをうけ、それを元に正しい課題や解法にアプローチすることができる」からだ。これはデジタルプロダクトにおける常識でもある。

特に1.課題熱量の不確実性については、もはや「プロダクトを創る前に検証できる、センサーの付いたプラットフォーム」が抱負に存在する。例えばプロトタイプをInstagramやメルカリ、Twitterで売ってみればいい。「お金を払ってまで解決したい熱量のある人」がどれだけ存在するか、リアルデータが得られる。

2.サイズの不確実性については、「100円で行ける100%安全な宇宙旅行」のような全く新しいプロダクトであれば流通させるまでわからないだろう。しかし多くのプロダクトは何かしら既存のユースケースを置き換えるものだ。であれば、マーケットサイズの上限はざっくり予測できる。いまから日本で革新的な牛丼屋を始めても、市場が既存の2倍になることはない。人口の統計とはもっとも予測が付きやすい指標であり、どこの・誰にが決まれば上限が予測つく。あとはシェアをどう取るか、の問題になる。ダブルジョパディの法則にすべてのマーケットが修練する。ある種、不確実性はほとんどない。

つまり、プロダクトのリリース後に「3. 解法の不確実性」を潰すことこそがプロダクトにとっての本当のスタートになる。

--

1/「既存ファネルのレートを数%ずつ積み上げるような改善仮説」ではなく、プロダクトの「バリューポジションそのものを検証する仮説」があったとする。しかし破壊的な変更となるために、ユーザーへ問う際のリスクが高い。
2/そういうときこそ「ABテスト」や「段階的リリース」を用いて、影響範囲をコントロールしつつ同期的に、バイアスの少ない複数のグループでテストをする。部分的に可逆的なリリースともいえる。しかし実は、このテスト自体が初期のスタートアップにおいてコストが大きいというジレンマがある。
3/どういったコストか。3つある。1つは組織におけるリソース配分コスト。大胆な実験だけに、多くのプロダクトリソースを割く訳にはいかない。日頃の積み重ねと、振り切った実験は表裏一体だ。どちらが最後に花開くかわからない。故にリソースの配分が難しく、この意思決定自体がコストを要する。
4/もう1つは獲得コスト。テストにおいて「統計学的に有意」といえるだけの母集団を確保するにはユーザーの流量が必要であり、この獲得にコストがかかる（有り余るオーガニック流量や広告宣伝費があればこのコストは無視できる）。
5/最後は実装コスト。精緻にグループをコントロールし、分析できるようにログを吐く実装が必要。Firebase AB Testingはこの問題を簡易に解消できるツールだが、β版ゆえかログの部分欠損も観測される。有料ツールは金も実装コストも掛かり、スクラッチのテスト基盤ならなおの実装コストがかかる。
6/もしあなたのスタートアップにログ分析に長けた人間がいない場合、さらに分析コストがかかってくる。導きたい結論を言語化し、それに対する実験計画を立て、ログ設計をし、集計し、認知バイアスのかからないよう結論を言語化する。
6/これらの「大胆な実験を初期に行う際のジレンマ」に対してどう向かうか。我々が見出した答えは「ishkawa」である。
7/ishkawaに実験計画と仕様を伝え、ぐっすりと眠って朝目覚めると、goで書かれたサーバー、swift/kotlinで書かれたクライアント、そしてテストコードも完備して状態で「テスト開始します」が聞ける。昼にSQLでも書いて、アイスでも食べたらだいたい終わり。さぁ、ishkawaをはじめよう。（了
